{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(160 * 120, 2056)\n",
    "        self.fc2 = nn.Linear(2056, 1028)\n",
    "        self.fc3 = nn.Linear(1028, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 160 * 120)\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(76800, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Reshape for fully connected layer\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class LightweightCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LightweightCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(32, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        # Reshape for fully connected layer\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "# Creating a CNN class\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(63936, 1024)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightweightCNN()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', 'labels']\n",
      "(3, 120, 160)\n",
      "['images', 'labels']\n"
     ]
    }
   ],
   "source": [
    "# Import training and validation dataset from npz file\n",
    "with np.load('/Users/jvelasquez/Virginia_Tech/Spring_2023/ECE_4806/ieee-robotics-2023-code/src/jetson_code/pedestal_classification/pedestal_color_orientation_dataset.npz') as data:\n",
    "    print(data.files)\n",
    "    images = data['images']\n",
    "    labels = data['labels']\n",
    "\n",
    "# Preprocess the images\n",
    "images = images.astype('float32') / 255\n",
    "print(images[0].shape)\n",
    "\n",
    "# Make labels shape (n, 1)\n",
    "#labels.reshape(labels.shape[0], 1)\n",
    "\n",
    "# Convert the numpy arrays to PyTorch tensors\n",
    "images_tensor = torch.from_numpy(images)\n",
    "labels_tensor = torch.from_numpy(labels)\n",
    "\n",
    "# Load the testing set\n",
    "with np.load('/Users/jvelasquez/Virginia_Tech/Spring_2023/ECE_4806/ieee-robotics-2023-code/src/jetson_code/pedestal_classification/pedestal_color_orientation_test_dataset.npz') as data:\n",
    "    print(data.files)\n",
    "    test_images = data['images']\n",
    "    test_labels = data['labels']\n",
    "\n",
    "test_images = test_images.astype('float32') / 255\n",
    "#test_labels = test_labels.reshape(test_labels.shape[0], 1)\n",
    "\n",
    "# Shuffle test_images and test_labels together\n",
    "p = np.random.permutation(len(test_images))\n",
    "test_images = test_images[p]\n",
    "test_labels = test_labels[p]\n",
    "\n",
    "# Convert the numpy arrays to PyTorch tensors\n",
    "test_images_tensor = torch.from_numpy(test_images)\n",
    "test_labels_tensor = torch.from_numpy(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset using the tensors\n",
    "dataset = torch.utils.data.TensorDataset(images_tensor, labels_tensor)\n",
    "\n",
    "# Take a portion of the the test images and labels and append them to the dataset\n",
    "portion = int(len(test_images_tensor) * 0.75)\n",
    "dataset = torch.utils.data.ConcatDataset([dataset, torch.utils.data.TensorDataset(test_images_tensor[:portion], test_labels_tensor[:portion])])\n",
    "\n",
    "# Take the other portion of the test images and labels and use them as the test set\n",
    "other_portion = int(len(test_images_tensor) - portion)\n",
    "test_set = torch.utils.data.TensorDataset(test_images_tensor[other_portion:], test_labels_tensor[other_portion:])\n",
    "\n",
    "# Define image transformations\n",
    "# Define the image transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(30),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "train_split = 0.8\n",
    "train_size = int(train_split * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# # Apply transformations to all images in the training set\n",
    "# train_transformed = torch.utils.data.Subset(train_set, train_set.indices)\n",
    "# train_transformed.dataset.transform = transform\n",
    "\n",
    "# # Apply transformations to all images in the validation set     \n",
    "# val_transformed = torch.utils.data.Subset(val_set, val_set.indices)\n",
    "# val_transformed.dataset.transform = transform\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# test_set = torch.utils.data.TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Apple MPS backend\n",
      "LightweightCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
      "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n",
      "torch.Size([1, 6])\n",
      "tensor([[ 0.0283,  0.0102,  0.2018, -0.1853, -0.0837, -0.1202]],\n",
      "       device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Check to see what device is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using the Apple MPS backend\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using the CUDA backend\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using the CPU backend\")\n",
    "    \n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "# Input a dummy tensor to the model\n",
    "dummy_input = torch.randn(1, 3, 120, 160, device=device)\n",
    "out = model(dummy_input)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "LightweightCNN                           [16, 6]                   --\n",
      "├─Conv2d: 1-1                            [16, 16, 60, 80]          448\n",
      "│    └─weight                                                      ├─432\n",
      "│    └─bias                                                        └─16\n",
      "├─MaxPool2d: 1-2                         [16, 16, 29, 39]          --\n",
      "├─Conv2d: 1-3                            [16, 32, 14, 19]          12,832\n",
      "│    └─weight                                                      ├─12,800\n",
      "│    └─bias                                                        └─32\n",
      "├─MaxPool2d: 1-4                         [16, 32, 6, 8]            --\n",
      "├─Conv2d: 1-5                            [16, 64, 2, 3]            51,264\n",
      "│    └─weight                                                      ├─51,200\n",
      "│    └─bias                                                        └─64\n",
      "├─MaxPool2d: 1-6                         [16, 64, 1, 1]            --\n",
      "├─Linear: 1-7                            [16, 32]                  2,080\n",
      "│    └─weight                                                      ├─2,048\n",
      "│    └─bias                                                        └─32\n",
      "├─Dropout: 1-8                           [16, 32]                  --\n",
      "├─Linear: 1-9                            [16, 6]                   198\n",
      "│    └─weight                                                      ├─192\n",
      "│    └─bias                                                        └─6\n",
      "==========================================================================================\n",
      "Total params: 66,822\n",
      "Trainable params: 66,822\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 93.98\n",
      "==========================================================================================\n",
      "Input size (MB): 3.69\n",
      "Forward/backward pass size (MB): 10.97\n",
      "Params size (MB): 0.27\n",
      "Estimated Total Size (MB): 14.93\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LightweightCNN                           [16, 6]                   --\n",
       "├─Conv2d: 1-1                            [16, 16, 60, 80]          448\n",
       "│    └─weight                                                      ├─432\n",
       "│    └─bias                                                        └─16\n",
       "├─MaxPool2d: 1-2                         [16, 16, 29, 39]          --\n",
       "├─Conv2d: 1-3                            [16, 32, 14, 19]          12,832\n",
       "│    └─weight                                                      ├─12,800\n",
       "│    └─bias                                                        └─32\n",
       "├─MaxPool2d: 1-4                         [16, 32, 6, 8]            --\n",
       "├─Conv2d: 1-5                            [16, 64, 2, 3]            51,264\n",
       "│    └─weight                                                      ├─51,200\n",
       "│    └─bias                                                        └─64\n",
       "├─MaxPool2d: 1-6                         [16, 64, 1, 1]            --\n",
       "├─Linear: 1-7                            [16, 32]                  2,080\n",
       "│    └─weight                                                      ├─2,048\n",
       "│    └─bias                                                        └─32\n",
       "├─Dropout: 1-8                           [16, 32]                  --\n",
       "├─Linear: 1-9                            [16, 6]                   198\n",
       "│    └─weight                                                      ├─192\n",
       "│    └─bias                                                        └─6\n",
       "==========================================================================================\n",
       "Total params: 66,822\n",
       "Trainable params: 66,822\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 93.98\n",
       "==========================================================================================\n",
       "Input size (MB): 3.69\n",
       "Forward/backward pass size (MB): 10.97\n",
       "Params size (MB): 0.27\n",
       "Estimated Total Size (MB): 14.93\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "summary(model, input_size=(batch_size, 3, 120, 160), verbose=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Train Loss: 1.7926, Train Acc: 16.86%, Val Loss: 1.7918, Val Acc: 17.00%, Test Loss: 1.7920, Test Acc: 15.72%\n",
      "Epoch [2/1000], Train Loss: 1.7883, Train Acc: 16.89%, Val Loss: 1.7874, Val Acc: 17.00%, Test Loss: 1.7891, Test Acc: 15.72%\n",
      "Epoch [3/1000], Train Loss: 1.7829, Train Acc: 16.86%, Val Loss: 1.7800, Val Acc: 17.00%, Test Loss: 1.7844, Test Acc: 15.72%\n",
      "Epoch [4/1000], Train Loss: 1.7730, Train Acc: 19.73%, Val Loss: 1.7654, Val Acc: 17.00%, Test Loss: 1.7748, Test Acc: 15.72%\n",
      "Epoch [5/1000], Train Loss: 1.7519, Train Acc: 29.56%, Val Loss: 1.7314, Val Acc: 30.48%, Test Loss: 1.7508, Test Acc: 22.23%\n",
      "Epoch [6/1000], Train Loss: 1.6898, Train Acc: 38.54%, Val Loss: 1.5886, Val Acc: 47.10%, Test Loss: 1.6423, Test Acc: 37.85%\n",
      "Epoch [7/1000], Train Loss: 1.4573, Train Acc: 40.47%, Val Loss: 1.2093, Val Acc: 42.95%, Test Loss: 1.3283, Test Acc: 32.06%\n",
      "Epoch [8/1000], Train Loss: 1.1959, Train Acc: 42.42%, Val Loss: 0.9808, Val Acc: 56.55%, Test Loss: 1.1643, Test Acc: 38.68%\n",
      "Epoch [9/1000], Train Loss: 0.9905, Train Acc: 48.69%, Val Loss: 0.7738, Val Acc: 63.10%, Test Loss: 0.9476, Test Acc: 58.74%\n",
      "Epoch [10/1000], Train Loss: 0.8503, Train Acc: 52.69%, Val Loss: 0.7080, Val Acc: 62.72%, Test Loss: 0.8525, Test Acc: 55.33%\n",
      "Epoch [11/1000], Train Loss: 0.7536, Train Acc: 58.59%, Val Loss: 0.6365, Val Acc: 77.71%, Test Loss: 0.7538, Test Acc: 61.53%\n",
      "Epoch [12/1000], Train Loss: 0.6953, Train Acc: 62.37%, Val Loss: 0.6021, Val Acc: 64.48%, Test Loss: 0.7400, Test Acc: 62.15%\n",
      "Epoch [13/1000], Train Loss: 0.6376, Train Acc: 66.37%, Val Loss: 0.5791, Val Acc: 65.49%, Test Loss: 0.7527, Test Acc: 61.84%\n",
      "Epoch [14/1000], Train Loss: 0.5931, Train Acc: 70.25%, Val Loss: 0.4901, Val Acc: 80.86%, Test Loss: 0.7026, Test Acc: 58.43%\n",
      "Epoch [15/1000], Train Loss: 0.5456, Train Acc: 72.46%, Val Loss: 0.4625, Val Acc: 76.07%, Test Loss: 0.7084, Test Acc: 58.95%\n",
      "Epoch [16/1000], Train Loss: 0.5345, Train Acc: 72.80%, Val Loss: 0.4358, Val Acc: 76.70%, Test Loss: 0.6910, Test Acc: 59.36%\n",
      "Epoch [17/1000], Train Loss: 0.5097, Train Acc: 72.93%, Val Loss: 0.4146, Val Acc: 76.45%, Test Loss: 0.6505, Test Acc: 62.98%\n",
      "Epoch [18/1000], Train Loss: 0.4732, Train Acc: 74.63%, Val Loss: 0.4443, Val Acc: 75.94%, Test Loss: 0.6745, Test Acc: 58.53%\n",
      "Epoch [19/1000], Train Loss: 0.4742, Train Acc: 75.10%, Val Loss: 0.3796, Val Acc: 76.95%, Test Loss: 0.6669, Test Acc: 60.70%\n",
      "Epoch [20/1000], Train Loss: 0.4614, Train Acc: 74.88%, Val Loss: 0.3775, Val Acc: 77.20%, Test Loss: 0.6822, Test Acc: 60.39%\n",
      "Epoch [21/1000], Train Loss: 0.4273, Train Acc: 77.12%, Val Loss: 0.3452, Val Acc: 84.51%, Test Loss: 0.6225, Test Acc: 64.74%\n",
      "Epoch [22/1000], Train Loss: 0.4257, Train Acc: 76.77%, Val Loss: 0.3771, Val Acc: 77.71%, Test Loss: 0.6546, Test Acc: 61.12%\n",
      "Epoch [23/1000], Train Loss: 0.4180, Train Acc: 76.65%, Val Loss: 0.3787, Val Acc: 78.97%, Test Loss: 0.6566, Test Acc: 63.60%\n",
      "Epoch [24/1000], Train Loss: 0.4152, Train Acc: 76.90%, Val Loss: 0.3373, Val Acc: 76.95%, Test Loss: 0.6189, Test Acc: 63.08%\n",
      "Epoch [25/1000], Train Loss: 0.4124, Train Acc: 76.05%, Val Loss: 0.3320, Val Acc: 77.46%, Test Loss: 0.6156, Test Acc: 62.67%\n",
      "Epoch [26/1000], Train Loss: 0.4198, Train Acc: 76.14%, Val Loss: 0.3487, Val Acc: 82.24%, Test Loss: 0.6365, Test Acc: 63.81%\n",
      "Epoch [27/1000], Train Loss: 0.4171, Train Acc: 75.92%, Val Loss: 0.3286, Val Acc: 83.50%, Test Loss: 0.6099, Test Acc: 66.49%\n",
      "Epoch [28/1000], Train Loss: 0.4001, Train Acc: 78.06%, Val Loss: 0.3384, Val Acc: 78.09%, Test Loss: 0.6109, Test Acc: 63.08%\n",
      "Epoch [29/1000], Train Loss: 0.3900, Train Acc: 76.90%, Val Loss: 0.3309, Val Acc: 78.09%, Test Loss: 0.6085, Test Acc: 64.43%\n",
      "Epoch [30/1000], Train Loss: 0.3829, Train Acc: 78.25%, Val Loss: 0.3413, Val Acc: 77.83%, Test Loss: 0.6374, Test Acc: 62.87%\n",
      "Epoch [31/1000], Train Loss: 0.3882, Train Acc: 78.32%, Val Loss: 0.3283, Val Acc: 77.83%, Test Loss: 0.6025, Test Acc: 63.50%\n",
      "Epoch [32/1000], Train Loss: 0.3748, Train Acc: 78.85%, Val Loss: 0.3331, Val Acc: 84.76%, Test Loss: 0.6394, Test Acc: 63.29%\n",
      "Epoch [33/1000], Train Loss: 0.3762, Train Acc: 79.86%, Val Loss: 0.3252, Val Acc: 82.37%, Test Loss: 0.6144, Test Acc: 65.15%\n",
      "Epoch [34/1000], Train Loss: 0.3752, Train Acc: 78.54%, Val Loss: 0.3231, Val Acc: 77.96%, Test Loss: 0.5917, Test Acc: 64.01%\n",
      "Epoch [35/1000], Train Loss: 0.3894, Train Acc: 77.18%, Val Loss: 0.3161, Val Acc: 83.38%, Test Loss: 0.5866, Test Acc: 64.22%\n",
      "Epoch [36/1000], Train Loss: 0.3762, Train Acc: 78.73%, Val Loss: 0.3155, Val Acc: 83.63%, Test Loss: 0.5679, Test Acc: 67.32%\n",
      "Epoch [37/1000], Train Loss: 0.3671, Train Acc: 79.89%, Val Loss: 0.3117, Val Acc: 80.98%, Test Loss: 0.5932, Test Acc: 66.18%\n",
      "Epoch [38/1000], Train Loss: 0.3629, Train Acc: 79.86%, Val Loss: 0.3355, Val Acc: 80.35%, Test Loss: 0.6384, Test Acc: 64.32%\n",
      "Epoch [39/1000], Train Loss: 0.3731, Train Acc: 79.14%, Val Loss: 0.3329, Val Acc: 79.35%, Test Loss: 0.6056, Test Acc: 63.50%\n",
      "Epoch [40/1000], Train Loss: 0.3702, Train Acc: 78.73%, Val Loss: 0.3186, Val Acc: 84.26%, Test Loss: 0.6098, Test Acc: 63.70%\n",
      "Epoch [41/1000], Train Loss: 0.3581, Train Acc: 80.21%, Val Loss: 0.3227, Val Acc: 82.49%, Test Loss: 0.6364, Test Acc: 63.70%\n",
      "Epoch [42/1000], Train Loss: 0.3609, Train Acc: 79.80%, Val Loss: 0.3707, Val Acc: 80.35%, Test Loss: 0.7151, Test Acc: 59.98%\n",
      "Epoch [43/1000], Train Loss: 0.3634, Train Acc: 80.14%, Val Loss: 0.3087, Val Acc: 81.61%, Test Loss: 0.5993, Test Acc: 65.67%\n",
      "Epoch [44/1000], Train Loss: 0.3614, Train Acc: 79.26%, Val Loss: 0.3068, Val Acc: 81.36%, Test Loss: 0.5905, Test Acc: 65.56%\n",
      "Epoch [45/1000], Train Loss: 0.3580, Train Acc: 80.08%, Val Loss: 0.3004, Val Acc: 84.01%, Test Loss: 0.5741, Test Acc: 67.84%\n",
      "Epoch [46/1000], Train Loss: 0.3587, Train Acc: 79.92%, Val Loss: 0.2931, Val Acc: 84.63%, Test Loss: 0.5713, Test Acc: 64.63%\n",
      "Epoch [47/1000], Train Loss: 0.3521, Train Acc: 80.74%, Val Loss: 0.2866, Val Acc: 83.50%, Test Loss: 0.5535, Test Acc: 69.70%\n",
      "Epoch [48/1000], Train Loss: 0.3418, Train Acc: 81.82%, Val Loss: 0.2833, Val Acc: 84.63%, Test Loss: 0.5549, Test Acc: 68.15%\n",
      "Epoch [49/1000], Train Loss: 0.3447, Train Acc: 81.66%, Val Loss: 0.2864, Val Acc: 86.90%, Test Loss: 0.5706, Test Acc: 69.70%\n",
      "Epoch [50/1000], Train Loss: 0.3385, Train Acc: 81.47%, Val Loss: 0.2734, Val Acc: 86.90%, Test Loss: 0.5431, Test Acc: 71.56%\n",
      "Epoch [51/1000], Train Loss: 0.3455, Train Acc: 81.75%, Val Loss: 0.3087, Val Acc: 83.12%, Test Loss: 0.6530, Test Acc: 59.15%\n",
      "Epoch [52/1000], Train Loss: 0.3362, Train Acc: 81.00%, Val Loss: 0.3020, Val Acc: 81.61%, Test Loss: 0.5665, Test Acc: 69.60%\n",
      "Epoch [53/1000], Train Loss: 0.3432, Train Acc: 81.63%, Val Loss: 0.2756, Val Acc: 85.64%, Test Loss: 0.5632, Test Acc: 67.11%\n",
      "Epoch [54/1000], Train Loss: 0.3315, Train Acc: 82.54%, Val Loss: 0.2742, Val Acc: 86.78%, Test Loss: 0.5481, Test Acc: 68.36%\n",
      "Epoch [55/1000], Train Loss: 0.3374, Train Acc: 81.94%, Val Loss: 0.2807, Val Acc: 88.66%, Test Loss: 0.5702, Test Acc: 66.29%\n",
      "Epoch [56/1000], Train Loss: 0.3422, Train Acc: 81.50%, Val Loss: 0.2752, Val Acc: 86.65%, Test Loss: 0.5449, Test Acc: 67.63%\n",
      "Epoch [57/1000], Train Loss: 0.3501, Train Acc: 81.00%, Val Loss: 0.2691, Val Acc: 86.02%, Test Loss: 0.5463, Test Acc: 69.29%\n",
      "Epoch [58/1000], Train Loss: 0.3397, Train Acc: 81.50%, Val Loss: 0.2680, Val Acc: 84.38%, Test Loss: 0.5348, Test Acc: 69.80%\n",
      "Epoch [59/1000], Train Loss: 0.3283, Train Acc: 82.10%, Val Loss: 0.2846, Val Acc: 87.28%, Test Loss: 0.5791, Test Acc: 69.70%\n",
      "Epoch [60/1000], Train Loss: 0.3302, Train Acc: 82.26%, Val Loss: 0.2770, Val Acc: 85.26%, Test Loss: 0.5505, Test Acc: 66.70%\n",
      "Epoch [61/1000], Train Loss: 0.3228, Train Acc: 82.98%, Val Loss: 0.2899, Val Acc: 81.74%, Test Loss: 0.5437, Test Acc: 68.05%\n",
      "Epoch [62/1000], Train Loss: 0.3419, Train Acc: 81.75%, Val Loss: 0.3921, Val Acc: 78.21%, Test Loss: 0.7417, Test Acc: 62.56%\n",
      "Epoch [63/1000], Train Loss: 0.3603, Train Acc: 81.06%, Val Loss: 0.2918, Val Acc: 86.15%, Test Loss: 0.6027, Test Acc: 68.15%\n",
      "Epoch [64/1000], Train Loss: 0.3313, Train Acc: 82.98%, Val Loss: 0.2704, Val Acc: 86.52%, Test Loss: 0.5360, Test Acc: 70.84%\n",
      "Epoch [65/1000], Train Loss: 0.3281, Train Acc: 82.79%, Val Loss: 0.2529, Val Acc: 89.04%, Test Loss: 0.5294, Test Acc: 70.94%\n",
      "Epoch [66/1000], Train Loss: 0.3044, Train Acc: 84.46%, Val Loss: 0.2745, Val Acc: 87.28%, Test Loss: 0.5878, Test Acc: 69.18%\n",
      "Epoch [67/1000], Train Loss: 0.3301, Train Acc: 83.30%, Val Loss: 0.2646, Val Acc: 89.55%, Test Loss: 0.5309, Test Acc: 72.08%\n",
      "Epoch [68/1000], Train Loss: 0.3077, Train Acc: 84.40%, Val Loss: 0.2366, Val Acc: 89.80%, Test Loss: 0.5154, Test Acc: 72.39%\n",
      "Epoch [69/1000], Train Loss: 0.3290, Train Acc: 82.35%, Val Loss: 0.2800, Val Acc: 87.28%, Test Loss: 0.6087, Test Acc: 65.05%\n",
      "Epoch [70/1000], Train Loss: 0.3202, Train Acc: 83.90%, Val Loss: 0.2591, Val Acc: 87.03%, Test Loss: 0.5477, Test Acc: 71.15%\n",
      "Epoch [71/1000], Train Loss: 0.2957, Train Acc: 84.81%, Val Loss: 0.2282, Val Acc: 89.29%, Test Loss: 0.5275, Test Acc: 71.77%\n",
      "Epoch [72/1000], Train Loss: 0.2977, Train Acc: 85.35%, Val Loss: 0.2628, Val Acc: 84.76%, Test Loss: 0.5325, Test Acc: 68.87%\n",
      "Epoch [73/1000], Train Loss: 0.3153, Train Acc: 83.71%, Val Loss: 0.3051, Val Acc: 79.22%, Test Loss: 0.5578, Test Acc: 69.18%\n",
      "Epoch [74/1000], Train Loss: 0.3184, Train Acc: 84.37%, Val Loss: 0.2540, Val Acc: 89.42%, Test Loss: 0.5907, Test Acc: 69.49%\n",
      "Epoch [75/1000], Train Loss: 0.2824, Train Acc: 85.35%, Val Loss: 0.2121, Val Acc: 91.18%, Test Loss: 0.5033, Test Acc: 71.56%\n",
      "Epoch [76/1000], Train Loss: 0.3166, Train Acc: 83.80%, Val Loss: 0.2583, Val Acc: 86.65%, Test Loss: 0.5218, Test Acc: 72.49%\n",
      "Epoch [77/1000], Train Loss: 0.2852, Train Acc: 85.82%, Val Loss: 0.2381, Val Acc: 89.92%, Test Loss: 0.5614, Test Acc: 71.35%\n",
      "Epoch [78/1000], Train Loss: 0.2979, Train Acc: 85.28%, Val Loss: 0.2228, Val Acc: 89.17%, Test Loss: 0.4839, Test Acc: 75.59%\n",
      "Epoch [79/1000], Train Loss: 0.2702, Train Acc: 86.70%, Val Loss: 0.1912, Val Acc: 92.44%, Test Loss: 0.4789, Test Acc: 77.56%\n",
      "Epoch [80/1000], Train Loss: 0.2783, Train Acc: 86.23%, Val Loss: 0.1703, Val Acc: 93.07%, Test Loss: 0.4576, Test Acc: 78.59%\n",
      "Epoch [81/1000], Train Loss: 0.2540, Train Acc: 87.52%, Val Loss: 0.1752, Val Acc: 92.44%, Test Loss: 0.4502, Test Acc: 78.49%\n",
      "Epoch [82/1000], Train Loss: 0.2465, Train Acc: 89.22%, Val Loss: 0.1774, Val Acc: 92.57%, Test Loss: 0.4788, Test Acc: 75.49%\n",
      "Epoch [83/1000], Train Loss: 0.2977, Train Acc: 84.94%, Val Loss: 0.1740, Val Acc: 92.32%, Test Loss: 0.4542, Test Acc: 76.42%\n",
      "Epoch [84/1000], Train Loss: 0.2399, Train Acc: 88.21%, Val Loss: 0.2781, Val Acc: 83.75%, Test Loss: 0.5723, Test Acc: 71.25%\n",
      "Epoch [85/1000], Train Loss: 0.2545, Train Acc: 87.24%, Val Loss: 0.1731, Val Acc: 91.56%, Test Loss: 0.4878, Test Acc: 74.25%\n",
      "Epoch [86/1000], Train Loss: 0.2447, Train Acc: 88.06%, Val Loss: 0.1960, Val Acc: 89.92%, Test Loss: 0.4696, Test Acc: 76.01%\n",
      "Epoch [87/1000], Train Loss: 0.2387, Train Acc: 88.69%, Val Loss: 0.1970, Val Acc: 90.68%, Test Loss: 0.5064, Test Acc: 71.35%\n",
      "Epoch [88/1000], Train Loss: 0.2360, Train Acc: 89.35%, Val Loss: 0.1833, Val Acc: 92.19%, Test Loss: 0.5096, Test Acc: 73.94%\n",
      "Epoch [89/1000], Train Loss: 0.2577, Train Acc: 87.61%, Val Loss: 0.1964, Val Acc: 90.81%, Test Loss: 0.4839, Test Acc: 76.11%\n",
      "Epoch [90/1000], Train Loss: 0.2300, Train Acc: 89.06%, Val Loss: 0.1431, Val Acc: 94.08%, Test Loss: 0.4408, Test Acc: 76.84%\n",
      "Epoch [91/1000], Train Loss: 0.2118, Train Acc: 90.48%, Val Loss: 0.2030, Val Acc: 90.18%, Test Loss: 0.4568, Test Acc: 76.42%\n",
      "Epoch [92/1000], Train Loss: 0.1946, Train Acc: 91.43%, Val Loss: 0.3570, Val Acc: 83.12%, Test Loss: 0.6849, Test Acc: 69.29%\n",
      "Epoch [93/1000], Train Loss: 0.2856, Train Acc: 87.05%, Val Loss: 0.2814, Val Acc: 85.14%, Test Loss: 0.5658, Test Acc: 71.87%\n",
      "Epoch [94/1000], Train Loss: 0.2306, Train Acc: 89.47%, Val Loss: 0.1700, Val Acc: 91.81%, Test Loss: 0.5068, Test Acc: 72.80%\n",
      "Epoch [95/1000], Train Loss: 0.2516, Train Acc: 87.80%, Val Loss: 0.1318, Val Acc: 94.33%, Test Loss: 0.4181, Test Acc: 77.87%\n",
      "Epoch [96/1000], Train Loss: 0.2050, Train Acc: 90.86%, Val Loss: 0.1618, Val Acc: 92.44%, Test Loss: 0.4845, Test Acc: 74.56%\n",
      "Epoch [97/1000], Train Loss: 0.1902, Train Acc: 91.24%, Val Loss: 0.1194, Val Acc: 95.34%, Test Loss: 0.4041, Test Acc: 80.04%\n",
      "Epoch [98/1000], Train Loss: 0.1928, Train Acc: 91.52%, Val Loss: 0.1158, Val Acc: 94.21%, Test Loss: 0.3969, Test Acc: 80.77%\n",
      "Epoch [99/1000], Train Loss: 0.1860, Train Acc: 91.59%, Val Loss: 0.1308, Val Acc: 94.33%, Test Loss: 0.4265, Test Acc: 77.97%\n",
      "Epoch [100/1000], Train Loss: 0.2200, Train Acc: 90.14%, Val Loss: 0.1279, Val Acc: 94.33%, Test Loss: 0.4208, Test Acc: 80.04%\n",
      "Epoch [101/1000], Train Loss: 0.2205, Train Acc: 90.07%, Val Loss: 0.1927, Val Acc: 91.69%, Test Loss: 0.5116, Test Acc: 75.70%\n",
      "Epoch [102/1000], Train Loss: 0.2039, Train Acc: 90.07%, Val Loss: 0.1715, Val Acc: 93.58%, Test Loss: 0.5329, Test Acc: 76.42%\n",
      "Epoch [103/1000], Train Loss: 0.1879, Train Acc: 91.74%, Val Loss: 0.1193, Val Acc: 93.70%, Test Loss: 0.4134, Test Acc: 77.87%\n",
      "Epoch [104/1000], Train Loss: 0.1756, Train Acc: 92.47%, Val Loss: 0.1145, Val Acc: 95.09%, Test Loss: 0.3747, Test Acc: 81.49%\n",
      "Epoch [105/1000], Train Loss: 0.2032, Train Acc: 90.67%, Val Loss: 0.1197, Val Acc: 93.83%, Test Loss: 0.4208, Test Acc: 80.97%\n",
      "Epoch [106/1000], Train Loss: 0.1703, Train Acc: 92.31%, Val Loss: 0.1062, Val Acc: 95.09%, Test Loss: 0.3967, Test Acc: 81.90%\n",
      "Epoch [107/1000], Train Loss: 0.1827, Train Acc: 91.27%, Val Loss: 0.1536, Val Acc: 93.45%, Test Loss: 0.4599, Test Acc: 77.87%\n",
      "Epoch [108/1000], Train Loss: 0.1940, Train Acc: 91.36%, Val Loss: 0.1099, Val Acc: 94.33%, Test Loss: 0.3887, Test Acc: 82.11%\n",
      "Epoch [109/1000], Train Loss: 0.1683, Train Acc: 91.96%, Val Loss: 0.1735, Val Acc: 91.56%, Test Loss: 0.4659, Test Acc: 75.18%\n",
      "Epoch [110/1000], Train Loss: 0.1662, Train Acc: 92.53%, Val Loss: 0.1011, Val Acc: 95.59%, Test Loss: 0.3574, Test Acc: 82.73%\n",
      "Epoch [111/1000], Train Loss: 0.1769, Train Acc: 92.28%, Val Loss: 0.1089, Val Acc: 93.83%, Test Loss: 0.4024, Test Acc: 80.66%\n",
      "Epoch [112/1000], Train Loss: 0.1585, Train Acc: 92.63%, Val Loss: 0.1947, Val Acc: 90.18%, Test Loss: 0.4929, Test Acc: 77.97%\n",
      "Epoch [113/1000], Train Loss: 0.1765, Train Acc: 92.22%, Val Loss: 0.1311, Val Acc: 93.32%, Test Loss: 0.4697, Test Acc: 78.70%\n",
      "Epoch [114/1000], Train Loss: 0.2570, Train Acc: 87.74%, Val Loss: 0.1118, Val Acc: 94.58%, Test Loss: 0.3973, Test Acc: 78.90%\n",
      "Epoch [115/1000], Train Loss: 0.1658, Train Acc: 92.50%, Val Loss: 0.1059, Val Acc: 95.34%, Test Loss: 0.3479, Test Acc: 83.56%\n",
      "Epoch [116/1000], Train Loss: 0.1693, Train Acc: 92.18%, Val Loss: 0.1227, Val Acc: 94.58%, Test Loss: 0.3757, Test Acc: 81.90%\n",
      "Epoch [117/1000], Train Loss: 0.1784, Train Acc: 91.74%, Val Loss: 0.1030, Val Acc: 95.47%, Test Loss: 0.3515, Test Acc: 83.45%\n",
      "Epoch [118/1000], Train Loss: 0.1502, Train Acc: 93.00%, Val Loss: 0.1086, Val Acc: 94.96%, Test Loss: 0.3820, Test Acc: 80.14%\n",
      "Epoch [119/1000], Train Loss: 0.1657, Train Acc: 92.25%, Val Loss: 0.1619, Val Acc: 93.45%, Test Loss: 0.5158, Test Acc: 76.22%\n",
      "Epoch [120/1000], Train Loss: 0.1725, Train Acc: 92.09%, Val Loss: 0.1426, Val Acc: 93.83%, Test Loss: 0.4203, Test Acc: 81.70%\n",
      "Epoch [121/1000], Train Loss: 0.1598, Train Acc: 92.69%, Val Loss: 0.1063, Val Acc: 93.70%, Test Loss: 0.3868, Test Acc: 80.56%\n",
      "Epoch [122/1000], Train Loss: 0.1482, Train Acc: 93.26%, Val Loss: 0.0893, Val Acc: 95.84%, Test Loss: 0.3343, Test Acc: 86.25%\n",
      "Epoch [123/1000], Train Loss: 0.1501, Train Acc: 93.19%, Val Loss: 0.0886, Val Acc: 96.22%, Test Loss: 0.3163, Test Acc: 86.56%\n",
      "Epoch [124/1000], Train Loss: 0.1415, Train Acc: 93.19%, Val Loss: 0.1003, Val Acc: 95.34%, Test Loss: 0.4037, Test Acc: 82.63%\n",
      "Epoch [125/1000], Train Loss: 0.1506, Train Acc: 93.32%, Val Loss: 0.3647, Val Acc: 87.03%, Test Loss: 0.6027, Test Acc: 75.70%\n",
      "Epoch [126/1000], Train Loss: 0.2758, Train Acc: 87.39%, Val Loss: 0.1216, Val Acc: 93.95%, Test Loss: 0.3726, Test Acc: 83.97%\n",
      "Epoch [127/1000], Train Loss: 0.1582, Train Acc: 93.10%, Val Loss: 0.0912, Val Acc: 95.47%, Test Loss: 0.3356, Test Acc: 83.97%\n",
      "Epoch [128/1000], Train Loss: 0.1488, Train Acc: 92.91%, Val Loss: 0.0910, Val Acc: 95.59%, Test Loss: 0.3238, Test Acc: 84.28%\n",
      "Epoch [129/1000], Train Loss: 0.1469, Train Acc: 93.32%, Val Loss: 0.0931, Val Acc: 96.47%, Test Loss: 0.3252, Test Acc: 86.04%\n",
      "Epoch [130/1000], Train Loss: 0.1364, Train Acc: 93.92%, Val Loss: 0.0832, Val Acc: 95.72%, Test Loss: 0.3227, Test Acc: 84.90%\n",
      "Epoch [131/1000], Train Loss: 0.1413, Train Acc: 93.70%, Val Loss: 0.0948, Val Acc: 94.58%, Test Loss: 0.3818, Test Acc: 76.73%\n",
      "Epoch [132/1000], Train Loss: 0.1493, Train Acc: 93.19%, Val Loss: 0.0829, Val Acc: 96.85%, Test Loss: 0.3017, Test Acc: 87.18%\n",
      "Epoch [133/1000], Train Loss: 0.1382, Train Acc: 93.89%, Val Loss: 0.1096, Val Acc: 94.71%, Test Loss: 0.3266, Test Acc: 83.87%\n",
      "Epoch [134/1000], Train Loss: 0.1324, Train Acc: 94.80%, Val Loss: 0.0817, Val Acc: 95.59%, Test Loss: 0.3116, Test Acc: 85.11%\n",
      "Epoch [135/1000], Train Loss: 0.1427, Train Acc: 93.35%, Val Loss: 0.0898, Val Acc: 96.47%, Test Loss: 0.3194, Test Acc: 85.94%\n",
      "Epoch [136/1000], Train Loss: 0.1399, Train Acc: 93.73%, Val Loss: 0.0808, Val Acc: 96.85%, Test Loss: 0.2854, Test Acc: 87.28%\n",
      "Epoch [137/1000], Train Loss: 0.1434, Train Acc: 92.75%, Val Loss: 0.0813, Val Acc: 95.97%, Test Loss: 0.3068, Test Acc: 85.83%\n",
      "Epoch [138/1000], Train Loss: 0.1433, Train Acc: 93.76%, Val Loss: 0.0746, Val Acc: 96.10%, Test Loss: 0.2876, Test Acc: 87.49%\n",
      "Epoch [139/1000], Train Loss: 0.1347, Train Acc: 94.01%, Val Loss: 0.0721, Val Acc: 96.73%, Test Loss: 0.2913, Test Acc: 88.42%\n",
      "Epoch [140/1000], Train Loss: 0.1379, Train Acc: 93.60%, Val Loss: 0.0845, Val Acc: 95.47%, Test Loss: 0.3231, Test Acc: 84.80%\n",
      "Epoch [141/1000], Train Loss: 0.1255, Train Acc: 94.52%, Val Loss: 0.0677, Val Acc: 97.23%, Test Loss: 0.2626, Test Acc: 89.35%\n",
      "Epoch [142/1000], Train Loss: 0.1274, Train Acc: 94.23%, Val Loss: 0.0776, Val Acc: 96.22%, Test Loss: 0.3017, Test Acc: 85.21%\n",
      "Epoch [143/1000], Train Loss: 0.1273, Train Acc: 93.89%, Val Loss: 0.0796, Val Acc: 96.73%, Test Loss: 0.2930, Test Acc: 86.97%\n",
      "Epoch [144/1000], Train Loss: 0.1398, Train Acc: 93.35%, Val Loss: 0.1311, Val Acc: 93.70%, Test Loss: 0.3939, Test Acc: 80.97%\n",
      "Epoch [145/1000], Train Loss: 0.1471, Train Acc: 93.07%, Val Loss: 0.0794, Val Acc: 96.35%, Test Loss: 0.2850, Test Acc: 85.52%\n",
      "Epoch [146/1000], Train Loss: 0.1303, Train Acc: 94.33%, Val Loss: 0.0711, Val Acc: 96.73%, Test Loss: 0.2592, Test Acc: 88.42%\n",
      "Epoch [147/1000], Train Loss: 0.1353, Train Acc: 94.23%, Val Loss: 0.1614, Val Acc: 93.20%, Test Loss: 0.5052, Test Acc: 78.59%\n",
      "Epoch [148/1000], Train Loss: 0.1332, Train Acc: 94.04%, Val Loss: 0.0972, Val Acc: 96.10%, Test Loss: 0.2950, Test Acc: 86.66%\n",
      "Epoch [149/1000], Train Loss: 0.1451, Train Acc: 94.20%, Val Loss: 0.0867, Val Acc: 95.59%, Test Loss: 0.3111, Test Acc: 84.90%\n",
      "Epoch [150/1000], Train Loss: 0.1528, Train Acc: 93.22%, Val Loss: 0.0860, Val Acc: 96.60%, Test Loss: 0.2865, Test Acc: 87.18%\n",
      "Epoch [151/1000], Train Loss: 0.1179, Train Acc: 94.67%, Val Loss: 0.0834, Val Acc: 95.72%, Test Loss: 0.3442, Test Acc: 83.25%\n",
      "Epoch [152/1000], Train Loss: 0.1348, Train Acc: 93.98%, Val Loss: 0.0765, Val Acc: 96.73%, Test Loss: 0.2561, Test Acc: 89.25%\n",
      "Epoch [153/1000], Train Loss: 0.1357, Train Acc: 93.79%, Val Loss: 0.1031, Val Acc: 95.21%, Test Loss: 0.3210, Test Acc: 83.45%\n",
      "Epoch [154/1000], Train Loss: 0.1832, Train Acc: 91.59%, Val Loss: 0.0748, Val Acc: 96.35%, Test Loss: 0.2602, Test Acc: 88.11%\n",
      "Epoch [155/1000], Train Loss: 0.1257, Train Acc: 94.42%, Val Loss: 0.2140, Val Acc: 90.93%, Test Loss: 0.5559, Test Acc: 78.80%\n",
      "Epoch [156/1000], Train Loss: 0.1173, Train Acc: 94.71%, Val Loss: 0.0642, Val Acc: 97.48%, Test Loss: 0.2285, Test Acc: 90.69%\n",
      "Epoch [157/1000], Train Loss: 0.1365, Train Acc: 93.98%, Val Loss: 0.0714, Val Acc: 96.22%, Test Loss: 0.2782, Test Acc: 88.11%\n",
      "Epoch [158/1000], Train Loss: 0.1148, Train Acc: 94.93%, Val Loss: 0.0912, Val Acc: 95.59%, Test Loss: 0.3830, Test Acc: 83.66%\n",
      "Epoch [159/1000], Train Loss: 0.1177, Train Acc: 94.36%, Val Loss: 0.0803, Val Acc: 95.84%, Test Loss: 0.3078, Test Acc: 84.80%\n",
      "Epoch [160/1000], Train Loss: 0.1207, Train Acc: 94.33%, Val Loss: 0.0660, Val Acc: 97.23%, Test Loss: 0.2339, Test Acc: 89.35%\n",
      "Epoch [161/1000], Train Loss: 0.1237, Train Acc: 94.86%, Val Loss: 0.0585, Val Acc: 97.36%, Test Loss: 0.2204, Test Acc: 90.69%\n",
      "Epoch [162/1000], Train Loss: 0.1229, Train Acc: 94.36%, Val Loss: 0.0651, Val Acc: 96.60%, Test Loss: 0.2371, Test Acc: 88.62%\n",
      "Epoch [163/1000], Train Loss: 0.1142, Train Acc: 94.52%, Val Loss: 0.0652, Val Acc: 97.48%, Test Loss: 0.2339, Test Acc: 90.59%\n",
      "Epoch [164/1000], Train Loss: 0.1140, Train Acc: 94.74%, Val Loss: 0.0558, Val Acc: 97.36%, Test Loss: 0.2154, Test Acc: 91.00%\n",
      "Epoch [165/1000], Train Loss: 0.1251, Train Acc: 94.11%, Val Loss: 0.0926, Val Acc: 96.47%, Test Loss: 0.3084, Test Acc: 86.87%\n",
      "Epoch [166/1000], Train Loss: 0.1173, Train Acc: 94.83%, Val Loss: 0.0498, Val Acc: 98.61%, Test Loss: 0.1929, Test Acc: 92.76%\n",
      "Epoch [167/1000], Train Loss: 0.1100, Train Acc: 94.93%, Val Loss: 0.0733, Val Acc: 96.85%, Test Loss: 0.2462, Test Acc: 89.56%\n",
      "Epoch [168/1000], Train Loss: 0.1111, Train Acc: 94.74%, Val Loss: 0.0569, Val Acc: 98.11%, Test Loss: 0.1974, Test Acc: 90.80%\n",
      "Epoch [169/1000], Train Loss: 0.1139, Train Acc: 94.80%, Val Loss: 0.1208, Val Acc: 95.59%, Test Loss: 0.3704, Test Acc: 85.42%\n",
      "Epoch [170/1000], Train Loss: 0.1101, Train Acc: 94.89%, Val Loss: 0.0844, Val Acc: 95.84%, Test Loss: 0.3096, Test Acc: 85.94%\n",
      "Epoch [171/1000], Train Loss: 0.1172, Train Acc: 95.02%, Val Loss: 0.0813, Val Acc: 96.22%, Test Loss: 0.2839, Test Acc: 88.00%\n",
      "Epoch [172/1000], Train Loss: 0.1359, Train Acc: 94.30%, Val Loss: 0.0562, Val Acc: 97.36%, Test Loss: 0.2297, Test Acc: 89.04%\n",
      "Epoch [173/1000], Train Loss: 0.1121, Train Acc: 95.08%, Val Loss: 0.0464, Val Acc: 98.49%, Test Loss: 0.1821, Test Acc: 92.45%\n",
      "Epoch [174/1000], Train Loss: 0.1016, Train Acc: 95.59%, Val Loss: 0.0503, Val Acc: 97.61%, Test Loss: 0.2078, Test Acc: 90.69%\n",
      "Epoch [175/1000], Train Loss: 0.0955, Train Acc: 95.46%, Val Loss: 0.0779, Val Acc: 97.73%, Test Loss: 0.2318, Test Acc: 91.31%\n",
      "Epoch [176/1000], Train Loss: 0.1186, Train Acc: 95.02%, Val Loss: 0.0547, Val Acc: 97.61%, Test Loss: 0.2030, Test Acc: 91.31%\n",
      "Epoch [177/1000], Train Loss: 0.1048, Train Acc: 95.52%, Val Loss: 0.0538, Val Acc: 97.61%, Test Loss: 0.2009, Test Acc: 90.69%\n",
      "Epoch [178/1000], Train Loss: 0.1082, Train Acc: 95.05%, Val Loss: 0.0574, Val Acc: 97.98%, Test Loss: 0.1953, Test Acc: 92.55%\n",
      "Epoch [179/1000], Train Loss: 0.1007, Train Acc: 94.93%, Val Loss: 0.0619, Val Acc: 97.98%, Test Loss: 0.2049, Test Acc: 92.45%\n",
      "Epoch [180/1000], Train Loss: 0.1345, Train Acc: 94.14%, Val Loss: 0.0851, Val Acc: 95.84%, Test Loss: 0.2879, Test Acc: 86.45%\n",
      "Epoch [181/1000], Train Loss: 0.1017, Train Acc: 95.56%, Val Loss: 0.0636, Val Acc: 96.60%, Test Loss: 0.2351, Test Acc: 88.00%\n",
      "Epoch [182/1000], Train Loss: 0.0881, Train Acc: 96.34%, Val Loss: 0.0471, Val Acc: 98.24%, Test Loss: 0.1562, Test Acc: 93.28%\n",
      "Epoch [183/1000], Train Loss: 0.1232, Train Acc: 94.48%, Val Loss: 0.0587, Val Acc: 97.48%, Test Loss: 0.2314, Test Acc: 89.87%\n",
      "Epoch [184/1000], Train Loss: 0.0983, Train Acc: 95.78%, Val Loss: 0.0554, Val Acc: 98.11%, Test Loss: 0.1800, Test Acc: 92.45%\n",
      "Epoch [185/1000], Train Loss: 0.1040, Train Acc: 95.24%, Val Loss: 0.0461, Val Acc: 98.36%, Test Loss: 0.1813, Test Acc: 92.66%\n",
      "Epoch [186/1000], Train Loss: 0.0915, Train Acc: 95.68%, Val Loss: 0.0528, Val Acc: 98.49%, Test Loss: 0.1823, Test Acc: 93.17%\n",
      "Epoch [187/1000], Train Loss: 0.0937, Train Acc: 95.62%, Val Loss: 0.0505, Val Acc: 97.73%, Test Loss: 0.1719, Test Acc: 93.17%\n",
      "Epoch [188/1000], Train Loss: 0.1060, Train Acc: 95.43%, Val Loss: 0.0634, Val Acc: 96.98%, Test Loss: 0.2277, Test Acc: 89.76%\n",
      "Epoch [189/1000], Train Loss: 0.0954, Train Acc: 95.97%, Val Loss: 0.0558, Val Acc: 97.23%, Test Loss: 0.1855, Test Acc: 92.14%\n",
      "Epoch [190/1000], Train Loss: 0.0902, Train Acc: 95.84%, Val Loss: 0.0450, Val Acc: 98.74%, Test Loss: 0.1467, Test Acc: 94.83%\n",
      "Epoch [191/1000], Train Loss: 0.0948, Train Acc: 95.84%, Val Loss: 0.0488, Val Acc: 97.86%, Test Loss: 0.1885, Test Acc: 91.00%\n",
      "Epoch [192/1000], Train Loss: 0.1016, Train Acc: 95.12%, Val Loss: 0.0976, Val Acc: 95.84%, Test Loss: 0.2968, Test Acc: 87.38%\n",
      "Epoch [193/1000], Train Loss: 0.0908, Train Acc: 95.90%, Val Loss: 0.0586, Val Acc: 97.61%, Test Loss: 0.1861, Test Acc: 92.14%\n",
      "Epoch [194/1000], Train Loss: 0.0853, Train Acc: 96.00%, Val Loss: 0.0465, Val Acc: 97.73%, Test Loss: 0.1977, Test Acc: 92.04%\n",
      "Epoch [195/1000], Train Loss: 0.0939, Train Acc: 95.78%, Val Loss: 0.0506, Val Acc: 97.36%, Test Loss: 0.1964, Test Acc: 91.31%\n",
      "Epoch [196/1000], Train Loss: 0.0870, Train Acc: 96.38%, Val Loss: 0.0634, Val Acc: 97.48%, Test Loss: 0.2035, Test Acc: 92.45%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "# Create SummaryWriter for TensorBoard\n",
    "writer = SummaryWriter(log_dir='model_logs')\n",
    "\n",
    "# Write graph of the model to TensorBoard\n",
    "writer.add_graph(model, dummy_input)\n",
    "\n",
    "# Initialize lists to store loss and accuracy for each epoch\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "\n",
    "        # Send the data to mps\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # Write to TensorBoard for logging\n",
    "    # writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    # writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            # Send the data to mps\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_acc = 100 * correct_val / total_val\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    # Write to TensorBoard for logging\n",
    "    # writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    # writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "    \n",
    "    # Test\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            # Send the data to mps\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    test_acc = 100 * correct_test / total_test\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    # Write to TensorBoard for logging\n",
    "    # writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "    # writer.add_scalar('Accuracy/test', test_acc, epoch)\n",
    "\n",
    "    writer.add_scalars(f'loss', {\n",
    "    'train': train_loss,\n",
    "    'val': val_loss,\n",
    "    'test': test_loss,\n",
    "}, epoch)\n",
    "    \n",
    "    writer.add_scalars(f'accuracy', {\n",
    "    'train': train_acc,\n",
    "    'val': val_acc,\n",
    "    'test': test_acc,\n",
    "}, epoch)\n",
    "    \n",
    "    # Print statistics\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%, Val Loss: {:.4f}, Val Acc: {:.2f}%, Test Loss: {:.4f}, Test Acc: {:.2f}%'.format(epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class names\n",
    "classes = ['Green_Side', 'Green_Up', 'Red_Side', 'Red_Up', 'White_Side', 'White_Up']\n",
    "\n",
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_label = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        # Send the data to mps\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        output = model(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 5 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy curves for training, validation, and testing sets\n",
    "plt.plot(range(num_epochs), train_losses, label='Training Loss')\n",
    "plt.plot(range(num_epochs), val_losses, label='Validation Loss')\n",
    "plt.plot(range(num_epochs), test_losses, label='Testing Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(num_epochs), train_accs, label='Training Accuracy')\n",
    "plt.plot(range(num_epochs), val_accs, label='Validation Accuracy')\n",
    "plt.plot(range(num_epochs), test_accs, label='Testing Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the writer\n",
    "writer.close()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'lightweight_net_color_orientation_v3.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
