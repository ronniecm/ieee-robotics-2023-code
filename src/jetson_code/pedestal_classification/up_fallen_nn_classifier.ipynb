{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(160 * 120, 2056)\n",
    "        self.fc2 = nn.Linear(2056, 1028)\n",
    "        self.fc3 = nn.Linear(1028, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 160 * 120)\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(76800, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Reshape for fully connected layer\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class LightweightCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LightweightCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(17024, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        # Reshape for fully connected layer\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Creating a CNN class\n",
    "class ConvNeuralNet(nn.Module):\n",
    "\t#  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightweightCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', 'labels']\n",
      "(3, 120, 160)\n",
      "1500\n",
      "1500\n",
      "['images', 'labels']\n",
      "(3, 480, 640)\n",
      "378\n",
      "514\n"
     ]
    }
   ],
   "source": [
    "# Import dataset from npz file\n",
    "with np.load('/Users/jvelasquez/Virginia_Tech/Spring_2023/ECE_4806/pedestal_svm/upright_fallen_dataset_v6.npz') as data:\n",
    "    print(data.files)\n",
    "    images = data['images']\n",
    "    labels = data['labels']\n",
    "\n",
    "# Preprocess the images\n",
    "images = images.astype('float32') / 255\n",
    "print(images[0].shape)\n",
    "\n",
    "# Flatten the images\n",
    "# images = images.reshape(images.shape[0], -1)\n",
    "\n",
    "# Make labels shape (n, 1)\n",
    "labels = labels.reshape(labels.shape[0], 1).astype('float32')\n",
    "\n",
    "print(np.count_nonzero(labels == 1))\n",
    "print(np.count_nonzero(labels == 0))\n",
    "\n",
    "# Convert the numpy arrays to PyTorch tensors\n",
    "images_tensor = torch.from_numpy(images).to(\"mps\")\n",
    "labels_tensor = torch.from_numpy(labels).to(\"mps\")\n",
    "\n",
    "#images_tensor = torch.from_numpy(images)\n",
    "#labels_tensor = torch.from_numpy(labels)\n",
    "\n",
    "\n",
    "# Define the dataset using the tensors\n",
    "dataset = torch.utils.data.TensorDataset(images_tensor, labels_tensor)\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), int(len(dataset)*0.2)])\n",
    "\n",
    "# Load the testing set\n",
    "with np.load('/Users/jvelasquez/Virginia_Tech/Spring_2023/ECE_4806/pedestal_svm/upright_fallen_dataset.npz') as data:\n",
    "    print(data.files)\n",
    "    test_images = data['images']\n",
    "    test_labels = data['labels']\n",
    "\n",
    "test_images = test_images.astype('float32') / 255\n",
    "test_labels = test_labels.reshape(test_labels.shape[0], 1).astype('float32')\n",
    "\n",
    "# Reshape all images in test_images to have channels first\n",
    "test_images = np.transpose(test_images, (0, 3, 1, 2))\n",
    "\n",
    "print(test_images[0].shape)\n",
    "\n",
    "print(np.count_nonzero(test_labels == 1))\n",
    "print(np.count_nonzero(test_labels == 0))\n",
    "\n",
    "# Convert the numpy arrays to PyTorch tensors\n",
    "test_images_tensor = torch.from_numpy(images).to(\"mps\")\n",
    "test_labels_tensor = torch.from_numpy(labels).to(\"mps\")\n",
    "\n",
    "# Define the test dataset using the tensors\n",
    "test_set = torch.utils.data.TensorDataset(images_tensor, labels_tensor)\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=16, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightweightCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=17024, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    \n",
    "    model.to(mps_device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# # Input a dummy tensor to the model\n",
    "# dummy_input = torch.randn(1, 3, 120, 160)\n",
    "# out = model(dummy_input)\n",
    "# print(out.shape)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.5710, Train Acc: 68.00%, Val Loss: 0.4024, Val Acc: 82.33%, Test Loss: 0.4060, Test Acc: 82.03%\n",
      "Epoch [2/10], Train Loss: 0.3046, Train Acc: 88.00%, Val Loss: 0.1963, Val Acc: 91.17%, Test Loss: 0.1971, Test Acc: 90.70%\n",
      "Epoch [3/10], Train Loss: 0.0940, Train Acc: 96.00%, Val Loss: 0.0497, Val Acc: 98.00%, Test Loss: 0.0532, Test Acc: 98.17%\n",
      "Epoch [4/10], Train Loss: 0.0403, Train Acc: 98.00%, Val Loss: 0.0104, Val Acc: 99.83%, Test Loss: 0.0113, Test Acc: 99.87%\n",
      "Epoch [5/10], Train Loss: 0.0232, Train Acc: 99.00%, Val Loss: 0.0217, Val Acc: 99.67%, Test Loss: 0.0212, Test Acc: 99.63%\n",
      "Epoch [6/10], Train Loss: 0.0103, Train Acc: 99.00%, Val Loss: 0.0024, Val Acc: 100.00%, Test Loss: 0.0030, Test Acc: 99.90%\n",
      "Epoch [7/10], Train Loss: 0.0074, Train Acc: 99.00%, Val Loss: 0.0016, Val Acc: 100.00%, Test Loss: 0.0018, Test Acc: 99.93%\n",
      "Epoch [8/10], Train Loss: 0.0114, Train Acc: 99.00%, Val Loss: 0.0034, Val Acc: 99.83%, Test Loss: 0.0036, Test Acc: 99.93%\n",
      "Epoch [9/10], Train Loss: 0.0115, Train Acc: 99.00%, Val Loss: 0.0123, Val Acc: 99.83%, Test Loss: 0.0122, Test Acc: 99.83%\n",
      "Epoch [10/10], Train Loss: 0.0050, Train Acc: 99.00%, Val Loss: 0.0008, Val Acc: 100.00%, Test Loss: 0.0007, Test Acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        #print(\"Outputs: \", outputs)\n",
    "        #print(\"Predicted: \", predicted)\n",
    "        #print(\"Labels: \", labels)\n",
    "        \n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    #print(correct_train, total_train)\n",
    "    train_acc = 100 * correct_train // total_train\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = 100 * correct_val / total_val\n",
    "    \n",
    "    # Test\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = 100 * correct_test / total_test\n",
    "    \n",
    "    # Print statistics\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%, Val Loss: {:.4f}, Val Acc: {:.2f}%, Test Loss: {:.4f}, Test Acc: {:.2f}%'.format(epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'lightweight_net_orientation.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "375d97cfcade92b3591f2950753814ced82f1b4401c46db252a260f186636a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
